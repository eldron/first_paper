#include "sma_driver.h"


static int timeout = 5 * HZ;
#define ETH_FRAME_LEN 1514    /* Max. octets in frame sans FCS */


static void sma_disable_msi(struct pci_dev * pdev)
{
    //ffwd_mac_device_info->msi_enable = 0;
    //wmb();
    //DPRINTK(DEBUG, "msi irq disable\n");

    unsigned char  byte;
    pci_read_config_byte( pdev, 0x52, &byte );
    byte = byte | 0x1;
    pci_write_config_byte( pdev, 0x52, byte );

}


static void sma_enable_msi(struct pci_dev * pdev)
{
    //ffwd_mac_device_info->msi_enable = 1;
   // wmb();

    //DPRINTK(DEBUG, "msi irq enable\n"); 

    unsigned char  byte;
    pci_read_config_byte( pdev, 0x52, &byte );
    byte = byte & ~( 0x01 );
    pci_write_config_byte( pdev, 0x52, byte );

}

uint8_t link_status;

static irqreturn_t sma_msi_handler( int irq, void* dev_id )
{
    if (link_status != ffwd_mac_device_info->link)
    {
        if (ffwd_mac_device_info->link)
        {
            netif_carrier_on( sma_driver_info.net_drv->ndev );
            netif_wake_queue( sma_driver_info.net_drv->ndev );
            printk( "%s link change up ok\n", sma_driver_info.net_drv->ndev->name );
        }
        else
        {
            netif_carrier_off( sma_driver_info.net_drv->ndev );
            netif_stop_queue( sma_driver_info.net_drv->ndev );
            printk( "%s link change down ok\n", sma_driver_info.net_drv->ndev->name );
        }
        link_status = ffwd_mac_device_info->link;
    }

    if (likely(napi_schedule_prep(&sma_driver_info.net_drv->napi))) 
    {
        sma_disable_msi(sma_driver_info.pcie_drv.pdev);
        __napi_schedule(&sma_driver_info.net_drv->napi);
    }

    return IRQ_HANDLED;
}


int rx_offset = 0;
int tx_offset = 0;
int free_offset = 0;

struct sk_buff * rx_skb_ring[MAC_ENTRY_DESC_NUM];
struct sk_buff * tx_skb_ring[MAC_ENTRY_DESC_NUM];

struct sk_buff * sma_alloc_skb_buff(struct net_device* ndev)
{
    unsigned long align;
    //struct sk_buff * skb = netdev_alloc_skb(ndev, MAC_PKT_SIZE);
    struct sk_buff* skb = __dev_alloc_skb( MAC_PKT_SIZE,GFP_DMA|GFP_ATOMIC);
	if (skb)
	{
	   	skb->dev = ndev;
        if (unlikely((align = (unsigned long) skb->data & (SMA_DMA_ALIGN - 1)))) 
            skb_reserve(skb, SMA_DMA_ALIGN - align);  
	}
    return skb;
}

static int 
sma_proc_rx_complete(struct napi_struct* napi,int budget)
{
    struct net_device* ndev = napi->dev;
    struct pci_dev * pdev = sma_driver_info.pcie_drv.pdev;
    struct sk_buff* skb , *new_skb;
    dma_addr_t mapping , phys;
    uint16_t len;

    int proc = 0;
    
    while(proc < budget)
    { 
        if(ffwd_mac_entry_desc_rx[rx_offset].state != FIFO_READABLE)
            break;

        skb = rx_skb_ring[rx_offset];
        phys = ffwd_mac_entry_desc_rx[rx_offset].address;
        len = ffwd_mac_entry_desc_rx[rx_offset].len;

        new_skb = sma_alloc_skb_buff(ndev);
        if(new_skb == NULL)
            panic("Alloc sk_buff faild\n");

        mapping = pci_map_single(pdev, new_skb->data,
                MAC_PKT_SIZE, PCI_DMA_FROMDEVICE);
                
    	if (pci_dma_mapping_error(pdev, mapping)) {
    		dev_kfree_skb(new_skb);
    		panic("pci_dma_mapping_error \n");
	    }
	    
        rx_skb_ring[rx_offset] = new_skb;
        pci_unmap_addr_set(&ffwd_mac_entry_desc_rx[rx_offset], address, mapping); 

        wmb();

        ffwd_mac_entry_desc_rx[rx_offset].state = FIFO_WRITABLE;
        rx_offset = (rx_offset + 1 ) & (MAC_ENTRY_DESC_NUM - 1);
        
        pci_unmap_single(pdev, phys, MAC_PKT_SIZE, PCI_DMA_FROMDEVICE);
		skb_put(skb, len);

        sma_driver_info.net_drv->stats.rx_packets++;
		skb->protocol = eth_type_trans(skb, ndev);
		//数据包传送给上传协议
		netif_receive_skb(skb);

		proc++;
    }

    return proc;
}

static int
sma_netdev_poll( struct napi_struct* napi, int budget )
{ 
    int proc = 0;
    
    proc = sma_proc_rx_complete(napi, budget);
    if(proc < budget)
    {
        napi_complete(napi);        
    }
    sma_enable_msi(sma_driver_info.pcie_drv.pdev);

    //printk("poll pktnum = %d\n",proc);
    
    return proc;
   
}

static int sma_netdev_open( struct net_device* dev )
{
    link_status = ffwd_mac_device_info->link;
    
    if (link_status)
    {
        netif_carrier_on( sma_driver_info.net_drv->ndev );
        netif_wake_queue( sma_driver_info.net_drv->ndev );
        printk( "%s link change up ok\n", dev->name );
    }
    else
    {
        netif_carrier_off( sma_driver_info.net_drv->ndev );
        netif_stop_queue( sma_driver_info.net_drv->ndev );
        printk( "%s link change down ok\n", dev->name );
    }  

    napi_enable(&sma_driver_info.net_drv->napi);

    sma_enable_msi(sma_driver_info.pcie_drv.pdev);
    
    printk("%s : link change up ok!\n", dev->name);        		

    return 0;
}

static inline void print_pkt(uint8_t* data, int len)
{
	int i;
 
	printk("addr %p len %d \n", data, len);
	for (i = 0; i <len; i++) {
		if ((i%4) == 0 && i !=0)
			printk(" ");
		if ((i%32) == 0 && i != 0)
			printk("\n");
		printk("%02x", data[i]);

	}
	printk("\n");
}

/* netdev_tx_t (*ndo_start_xmit)(struct sk_buff *skb,
*                               struct net_device *dev);
*  Called when a packet needs to be transmitted.
*  Must return NETDEV_TX_OK , NETDEV_TX_BUSY.
*        (can also return NETDEV_TX_LOCKED iff NETIF_F_LLTX)
*  Required can not be NULL.
*/
static netdev_tx_t sma_netdev_xmit( struct sk_buff* skb, struct net_device* dev )
{
     struct sk_buff* dma_skb;
    struct pci_dev * pdev = sma_driver_info.pcie_drv.pdev;
    
    while (free_offset != tx_offset)
    {
        if (ffwd_mac_entry_desc_tx[free_offset].state != FIFO_DONE )
            break;
        
        //pci_unmap_single( pdev, ffwd_mac_entry_desc_tx[free_offset].address, 
        //        ffwd_mac_entry_desc_tx[free_offset].len, DMA_TO_DEVICE );

        //dev_kfree_skb_any( tx_skb_ring[free_offset]);
        //tx_skb_ring[free_offset] = NULL;
        
        ffwd_mac_entry_desc_tx[free_offset].state = FIFO_WRITABLE;
        free_offset = ( free_offset + 1 ) & ( MAC_ENTRY_DESC_NUM -1 );
        barrier();
    }


    if(skb->len > ETH_FRAME_LEN)
    {
        sma_driver_info.net_drv->stats.tx_errors++;
        dev_kfree_skb_any( skb );
        return NETDEV_TX_OK;
    }
    //printk("data = %p len = %d headlen = %d \n", skb->data, 
    //                            skb->len, skb_headlen(skb));
    if(ffwd_mac_entry_desc_tx[tx_offset].state != FIFO_WRITABLE)
    {
        sma_driver_info.net_drv->stats.tx_errors++;
        dev_kfree_skb_any( skb );
        return NETDEV_TX_OK;
    }
    
	wmb();

    dma_skb = tx_skb_ring[tx_offset];
	memcpy(dma_skb->data,skb->data, skb->len);
	
	
    //tx_skb_ring[tx_offset] = skb;
    ffwd_mac_entry_desc_tx[tx_offset].len = skb->len ;
    //ffwd_mac_entry_desc_tx[tx_offset].address = 
    //    pci_map_single( pdev,(void*)skb->data,skb->len,DMA_TO_DEVICE );  
    ffwd_mac_entry_desc_tx[tx_offset].state = FIFO_READABLE;
    
    //if (pci_dma_mapping_error(pdev, ffwd_mac_entry_desc_tx[tx_offset].address)) 
    //    panic("pci_dma_mapping_error :Phys[%08x]\n",ffwd_mac_entry_desc_tx[tx_offset].address);
    //printk("bus address = %08x phys address = %08x\n",ffwd_mac_entry_desc_tx[tx_offset].address,virt_to_phys((void*)dma_skb->data));
    dev_kfree_skb_any(skb);     
    tx_offset = (tx_offset + 1) & (MAC_ENTRY_DESC_NUM - 1);
    //print_pkt(dma_skb->data,dma_skb->len);
    
    sma_driver_info.net_drv->stats.tx_packets++;
    wmb();
    
    dev->trans_start = jiffies;
    return NETDEV_TX_OK;
}

static int sma_netdev_close( struct net_device* dev )
{
    sma_disable_msi(sma_driver_info.pcie_drv.pdev);
    netif_carrier_off(dev);
    
    napi_disable(&sma_driver_info.net_drv->napi);

    netif_stop_queue( dev );
    
    return 0;
}


static struct net_device_stats * sma_netdev_get_stats(struct net_device* dev)
{
    return &sma_driver_info.net_drv->stats;

}

static void sma_set_multicast_list( struct net_device* netdev )
{
    if (netdev->flags & IFF_PROMISC)
    {
        ffwd_mac_device_info->promisc = 1;
    }
    else
    {
        ffwd_mac_device_info->promisc = 0;
    }    
}


static int sma_netdev_change_mtu(struct net_device* netdev, int new_mtu)
{
    DPRINTK(DEBUG, "not support ndo_change_mtu\r\n");
    return 0;
}



static void sma_netdev_timeout(struct net_device* dev)
{
    DPRINTK(DEBUG, "not support ndo_tx_timeout");
}

static const struct net_device_ops sma_netdev_ops =
{
  .ndo_open = sma_netdev_open,
  .ndo_stop = sma_netdev_close,
  .ndo_start_xmit = sma_netdev_xmit,
  .ndo_get_stats = sma_netdev_get_stats,
  .ndo_tx_timeout = sma_netdev_timeout,
  .ndo_set_multicast_list = sma_set_multicast_list,
  .ndo_change_mtu = sma_netdev_change_mtu
};

int sma_netdev_init_skb_pool(void)
{
    int i;
    struct sk_buff* skb;
    struct net_device* ndev = sma_driver_info.net_drv->ndev;
    struct pci_dev *pdev = sma_driver_info.pcie_drv.pdev;
    for(i = 0; i < MAC_ENTRY_DESC_NUM; i++ )
    {
        skb = sma_alloc_skb_buff(ndev);
        if(skb == NULL)
            panic("Alloc sk_buff faild\n");
            
        rx_skb_ring[i] = skb;
        ffwd_mac_entry_desc_rx[i].state = FIFO_WRITABLE;
        ffwd_mac_entry_desc_rx[i].address = 
            pci_map_single(pdev,( void * ) skb->data,MAC_PKT_SIZE,DMA_FROM_DEVICE );  

        skb = sma_alloc_skb_buff(ndev);
        if(skb == NULL)
            panic("Alloc sk_buff faild\n");
        tx_skb_ring[i] = skb ;
        ffwd_mac_entry_desc_tx[i].state = FIFO_WRITABLE;   
        ffwd_mac_entry_desc_tx[i].address = 
            pci_map_single(pdev,( void * ) skb->data,MAC_PKT_SIZE,DMA_TO_DEVICE );  
        
    }

    
    return 0;
}

int sma_netdev_free_skb_pool(void)
{
    int i;
    struct sk_buff* skb;
    struct net_device* ndev = sma_driver_info.net_drv->ndev;
    struct pci_dev *pdev = sma_driver_info.pcie_drv.pdev;
    for(i = 0; i < MAC_ENTRY_DESC_NUM; i++ )
    {
        if(rx_skb_ring[i])
        {
            pci_unmap_single( pdev, ffwd_mac_entry_desc_rx[i].address, 
                    MAC_PKT_SIZE, DMA_FROM_DEVICE );
            dev_kfree_skb_any( rx_skb_ring[i]);
        }
        if(tx_skb_ring[i])
        {
            pci_unmap_single( pdev, ffwd_mac_entry_desc_tx[i].address, 
                    MAC_PKT_SIZE, DMA_TO_DEVICE );
                    
            dev_kfree_skb_any( tx_skb_ring[i]);
        }
    }
    return 0;
}


int sma_netdev_init( sma_driver_info_t * driver_info )
{
    int ret = 0;
    sma_net_drv_info_t * net_drv;
    struct net_device* ndev;
    struct pci_dev * pdev;

    pdev = driver_info->pcie_drv.pdev;
    ndev = alloc_etherdev(sizeof(sma_net_drv_info_t));
    if (ndev == NULL)
    {
        DPRINTK(ERR, "Alloc etherdev faild\n" );
        return -1;
    }
    
    net_drv = netdev_priv(ndev);
    driver_info->net_drv = net_drv;

    net_drv->port = 0;
    net_drv->ndev = ndev;
    
    strncpy( ndev->name, "sma0", 8 );
    ndev->watchdog_timeo = timeout;
    
    netif_napi_add( ndev, &net_drv->napi, sma_netdev_poll, 64 );
    ndev->netdev_ops = &sma_netdev_ops;
    
    ndev->dev_addr[0] = ffwd_mac_device_info->mac_addr[0];
    ndev->dev_addr[1] = ffwd_mac_device_info->mac_addr[1];
    ndev->dev_addr[2] = ffwd_mac_device_info->mac_addr[2];
    ndev->dev_addr[3] = ffwd_mac_device_info->mac_addr[3];
    ndev->dev_addr[4] = ffwd_mac_device_info->mac_addr[4];
    ndev->dev_addr[5] = ffwd_mac_device_info->mac_addr[5];

    if(register_netdev(ndev))
    {
        DPRINTK(ERR, "Register_netdev faild err %d\n",ret);
        goto free_net_dev;
    } 

    DPRINTK(DEBUG, "register_netdev ok\n" );
    
    if(request_irq(pdev->irq, sma_msi_handler, 0, "sma_pcie", (void *)pdev))
    {
        DPRINTK(ERR, "Request_irq: failed with err %d\n", ret );
        goto free_unregister_netdev;
    }
    
    DPRINTK(DEBUG, "request msi irq ok %d \n",  pdev->irq);

    sma_netdev_init_skb_pool();
    
    DPRINTK(DEBUG, "Netdevice %s init ok\n", ndev->name );
    
    return 0;       

free_unregister_netdev:
    unregister_netdev(ndev);
free_net_dev:
    free_netdev(ndev);

    return -1;
}

void sma_netdev_release( sma_driver_info_t * driver_info )
{
    sma_netdev_free_skb_pool();

    sma_disable_msi(sma_driver_info.pcie_drv.pdev);
    
    free_irq(driver_info->pcie_drv.pdev->irq, driver_info->pcie_drv.pdev);

    unregister_netdev(driver_info->net_drv->ndev);

    free_netdev(driver_info->net_drv->ndev);
    
    DPRINTK(ERR, "free_netdev\r\n" );
}

